
```{r libraries,include=FALSE}
library(knitr)
```


# Exploring Patterns + forecasting techniques

*This chapter will elaborate on how one identify patterns in data thus how to account for this. Thus, we are looking into smoothing methods and moving averages*

*Additionally, we will explore how we select forecasting methods*

**Literature:**

+ HW: Exploring Data Patterns and an Introduction to Forecasting Techniques
+ HW: Moving Averages and Smoothing Methods
+ Armstrong, J.S. (2001) “Selecting Forecast Methods”, In Principles of Forecasting: A Handbook for Researchers and Practitioners (Ed. J. Scott Armstrong), Kluwer

## The forecasting process

*The following describe the forecasting process, hence what one must consider before performing the forecast and ultimately using the forecasts, the purpose of the process is to make sure that the forecast is reliable*

1. Specify objectives
    + Reason for the forecast
    + Applications based on the forecast
    + Good communication between all those involved
    
2. Determine what to forecast
    + Based on set objectives, choose key indicator(s)
    + *Example: domestic sales, export sales, or even both?*
    
3. Identify time dimension
    + Length and periodicity of the forecast
    + Desired frequency
    + Urgency of the forecast
    + Planning of the forecast
    
4. Data considerations
    + Available and quantity of the data
    + Internal vs. external data
    + Desired frequency in data (annual, quarterly, monthly)
    + *Example: Dollar sales instead of unit sales*
    
5. Model selection
    + The pattern exhibited by the data
    + The quantity of historic data available
    + The length of the forecast horizon
    
```{r,echo=FALSE,fig.cap="Model Selection"}
include_graphics("Images/04/ModelSelection.png")
```

6. Model evaluation
    + Testing the models on the series to be forecast
    + Checking how each model works 'in sample'
    + Measures such as MSE, RMSE, etc. used to rank models
    + Fit (in sample) vs. accuracy (out of sample)
    
7. Forecast preparation
    + Based on the selected model, obtain the forecast
    + Keep possibly competing models
    + See if their combination yields mode accuracy
    
8. Presentation of forecast result
    + Clear communication
    + Keep it as simple as possible
    + Visual aids to support the findings
    
9. Tracking results
    + Comparison of forecasts to actual values
    + Re-specify the selected model(s) over time if necessary
    + Try other model combinations to keep the accuracy level intact
    
**Conclusion:** One should realize that it is an iterative process, that one must be aware of.


## Data Patterns and terminology

*Basically the data is assumed to consist of up to four components, that is:*

1. Trend
    + Long-term change in the level of data
    + Positive vs. negative trends
    + Stationary series *have no trend*
    + *Example: Increasing technology leading to increase in productivity*
    
2. Seasonal
    + Repeated regular variation the level of data
    + *Example: Number of tourists in Mallorca*
    
3. Cyclical
    + Wavelike upward and downward movements around the long-term trend
    + Longer duration than seasonal fluctuations
    + *Example: Business cycles*
    + *Note, this is very often to identify*

4. Irregular
    + Random fluctuations
    + Possibly carrying more dynamics than just deterministic ones
    + Hardest to capture in a forecasting model
    
The four components may look similar to this:

```{r,echo=FALSE,fig.cap="Components in a timeseries"}
include_graphics("Images/04/Components.png")
```


### Terminology

$Y_t$: Denotes a time series variable

$\hat{Y_t}$: Denotes the foretasted value of $Y_t$ 

$e_t=Y_t-\hat{Y_t}$: Denotes the residual or the forecast error.

$Y_{t-k}$: Denotes a time series variable lagged by *k* periods.

#### Autocorrelation

**Autocorrelation**: is the correlation between a time series and its past (lagged) observations. To identify this, one can merely compare the lagged values as a series for itself, hence comparing actual time series against the lagged time series. This can be written as:

$$r_k=\frac{\sum_{t=k+1}^n\left(Y_{t\ }-\hat{Y}\right)}{\sum_{t=1}^n\left(Y_t-\hat{Y}\right)^{^2}}$$

Where $k = 0,1,2,...$, hence take on numbers, typically whole numbers, as the result must be measurable.

We assess autocorrelation to identify if the data have a trend, seasons, cycles or it is random? If we have seasons, trends or cycles, we must make the model account for this, otherwise one is prone to have a model where it is just implicitly correlated, but that is merely due to the autocorrelation, as it says in the word, it is automatically correlated, but that also implies, that it is not necessarily caused by the data, but rather other factors, often we see macro factors, that have an influence, e.g. an economic book.

Autocorrelation can be plotted using an autocorrelation function (ACF) or merely by using a correlogram, which is a k-period plot of the autocorelation, that looks like the following:

```{r,echo=FALSE,fig.cap="Correlogram Example"}
include_graphics("Images/04/CorrelogramExample.png")
```

Where one wants to be within the upper and lower level.

**Manually testing for autocorrelation**

One must:

1. Calculate $r_k$
2. Calculate $SE(r_k)$
3. Hypothesis: $H0 : \rho=0$, $H0 : \rho≠0$
    + We apply t-test
    
Where:
$$SE\left(r_k\right)=\sqrt{\left\{\frac{1+2\sum_{i=1}^{k-1}r_i^2}{n}\right\}}$$
Although, with normal approximation
$$SE\left(r_k\right)=\frac{1}{\sqrt{n-k}}$$

and test statistic equal
$$t=\frac{r_k}{SE(r_k)}$$

Thence one merely must look up the cut off values and assess if there is statistical evidance for autocorrelation or not.


**Alternative: Ljung-Box Q statistic**

$$Q\ =\ n\left(n+2\right)\sum_{k=1}^m\frac{r_k^2}{n-k}$$

Where *m* is the number of lags to be tested.

The Q statistic is commonly used for testing correlation in the residuals of a forecast model and the comparison is mate to $X^2_{m-q}$, where q is the number of parameters in the model.


#### Random vs. correlated data

Randomness is important for forecast model residuals. One can write simple random model, as

$$Y_t=c+\epsilon_t$$

Where c is the component and $\epsilon_t$ is the random error comonent. That is assumed to be uncorrelated period to period.

#### Stationary vs. non stationary data

**Stationary series** is not trending, where is **non stationary series** is trending, can both be linear or exponential.

**The how is it solved?**

One can merely apply differencing of order k. That is equal to:

$$\Delta Y_t=Y_t-Y_{t-1}$$

One could also apply growth rates are log differencing instead.


## Data Patterns and Model Selection {#DataPatternsAndModelSelection}

*Here are some examples from the lectures*

+ Tend, no cycle, no seasonality
    + Holt's exponential Smoothing
    + Linear regression with trend
    
+ Trend, seasonality, cycle
    + Winters' exponential smoothing
    + Linear regression with trend and seasonal adjustment
    + Causal regression
    + Time-series decomposition
    
+ Non linear trend, no seasonality, no cycle
    + Non linear regression with trend
    + Causal regression
    + Holt's exponential smoothing
    
Learn more about the methods in section \@ref(ForecastMethods), where a collection of performance measures can be found in section \@ref(PerformanceMeasurements)
















